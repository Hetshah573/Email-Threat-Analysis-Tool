{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDjnrUsCZz57"
      },
      "outputs": [],
      "source": [
        "!curl https://ollama.ai/install.sh | sh"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import asyncio\n",
        "import threading\n",
        "import time\n",
        "\n",
        "os.environ['PATH'] += ':/usr/local/cuda/bin'\n",
        "os.environ['LD_LIBRARY_PATH'] = '/usr/lib64-nvidia:/usr/local/cuda/lib64'\n",
        "\n",
        "async def run_process(cmd, stdout=None, stderr=None):\n",
        "    print('>>> starting', *cmd)\n",
        "    process = await asyncio.create_subprocess_exec(\n",
        "        *cmd,\n",
        "        stdout=stdout or asyncio.subprocess.PIPE,\n",
        "        stderr=stderr or asyncio.subprocess.PIPE\n",
        "    )\n",
        "\n",
        "    if stdout is None and stderr is None:\n",
        "        async def pipe(lines):\n",
        "            async for line in lines:\n",
        "                print(line.decode().strip())\n",
        "\n",
        "        await asyncio.gather(\n",
        "            pipe(process.stdout),\n",
        "            pipe(process.stderr),\n",
        "        )\n",
        "    else:\n",
        "        await process.wait()\n",
        "\n",
        "async def start_ollama_serve():\n",
        "    await run_process(['ollama', 'serve'],\n",
        "                      stdout=open(os.devnull, 'w'),\n",
        "                      stderr=open(os.devnull, 'w'))\n",
        "\n",
        "def run_async_in_thread(loop, coro):\n",
        "    asyncio.set_event_loop(loop)\n",
        "    loop.run_until_complete(coro)\n",
        "    loop.close()\n",
        "\n",
        "new_loop = asyncio.new_event_loop()\n",
        "\n",
        "thread = threading.Thread(target=run_async_in_thread, args=(new_loop, start_ollama_serve()))\n",
        "thread.start()\n",
        "\n",
        "time.sleep(5)"
      ],
      "metadata": {
        "id": "gqn1nnD0aD5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install openai pydantic instructor ipywidgets beautifulsoup4 pandas tqdm chardet matplotlib seaborn wordcloud"
      ],
      "metadata": {
        "id": "BHVDWrtsaH8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "OLLAMA_MODEL = \"gemma2:9b-instruct-q4_K_M\"\n",
        "\n",
        "!ollama pull {OLLAMA_MODEL}"
      ],
      "metadata": {
        "id": "CJF6JZFWaPOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from enum import Enum\n",
        "from typing import List\n",
        "\n",
        "class PhishingProbability(str, Enum):\n",
        "    LOW = \"low\"\n",
        "    MEDIUM = \"medium\"\n",
        "    HIGH = \"high\"\n",
        "\n",
        "class SuspiciousElement(BaseModel):\n",
        "    element: str\n",
        "    reason: str\n",
        "\n",
        "class SimplePhishingAnalysis(BaseModel):\n",
        "    is_potential_phishing: bool\n",
        "    phishing_probability: PhishingProbability\n",
        "    suspicious_elements: List[SuspiciousElement]\n",
        "    recommended_actions: List[str]\n",
        "    explanation: str"
      ],
      "metadata": {
        "id": "f_bMdAwsaf02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import instructor\n",
        "\n",
        "\n",
        "def analyze_email(email_content: str) -> SimplePhishingAnalysis:\n",
        "    client = instructor.from_openai(\n",
        "      OpenAI(\n",
        "          base_url=\"http://127.0.0.1:11434/v1\",\n",
        "          api_key=\"ollama\",\n",
        "      ),\n",
        "      mode=instructor.Mode.JSON,\n",
        "  )\n",
        "\n",
        "    resp = client.chat.completions.create(\n",
        "        model=OLLAMA_MODEL,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are an advanced AI assistant specialized in cybersecurity, particularly in detecting and analyzing phishing attempts in emails. Your task is to analyze the provided email content and metadata to determine if it's a potential phishing attempt. You must provide your analysis in a structured format that matches the model.\",\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": email_content,\n",
        "            },\n",
        "        ],\n",
        "        response_model=SimplePhishingAnalysis,\n",
        "    )\n",
        "    return resp"
      ],
      "metadata": {
        "id": "bAqQ44aYbsft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML\n",
        "import ipywidgets as widgets\n",
        "\n",
        "email_input = widgets.Textarea(\n",
        "    value='',\n",
        "    placeholder='Paste the email content here...',\n",
        "    description='Email:',\n",
        "    disabled=False,\n",
        "    layout={'width': '100%', 'height': '200px'}\n",
        ")\n",
        "\n",
        "analyze_button = widgets.Button(\n",
        "    description='Analyze Email',\n",
        "    disabled=False,\n",
        "    button_style='primary',\n",
        "    tooltip='Click to analyze the email',\n",
        "    icon='check'\n",
        ")\n",
        "\n",
        "output = widgets.Output()\n",
        "\n",
        "def on_button_clicked(b):\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        print(\"Analyzing email...\")\n",
        "        try:\n",
        "            analysis = analyze_email(email_input.value)\n",
        "            display(HTML(format_analysis(analysis)))\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {str(e)}\")\n",
        "\n",
        "analyze_button.on_click(on_button_clicked)\n",
        "\n",
        "def format_analysis(analysis: SimplePhishingAnalysis) -> str:\n",
        "    color = \"red\" if analysis.is_potential_phishing else \"green\"\n",
        "    result = f\"\"\"\n",
        "    <h2 style=\"color: {color};\">{'Potential Phishing Detected' if analysis.is_potential_phishing else 'Likely Legitimate Email'}</h2>\n",
        "    <p><strong>Phishing Probability:</strong> {analysis.phishing_probability.value}</p>\n",
        "    <h3>Suspicious Elements:</h3>\n",
        "    <ul>\n",
        "    \"\"\"\n",
        "    for element in analysis.suspicious_elements:\n",
        "        result += f\"<li><strong>{element.element}:</strong> {element.reason}</li>\"\n",
        "    result += \"</ul>\"\n",
        "    result += f\"\"\"\n",
        "    <h3>Recommended Actions:</h3>\n",
        "    <ul>\n",
        "    \"\"\"\n",
        "    for action in analysis.recommended_actions:\n",
        "        result += f\"<li>{action}</li>\"\n",
        "    result += \"</ul>\"\n",
        "    result += f\"<h3>Explanation:</h3><p>{analysis.explanation}</p>\"\n",
        "    return result\n",
        "\n",
        "display(email_input, analyze_button, output)"
      ],
      "metadata": {
        "id": "ffMwziMHq_r0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}